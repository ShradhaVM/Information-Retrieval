{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38564bit072a762024a64c92ba65cc5a87cd38e8",
      "display_name": "Python 3.8.5 64-bit",
      "language": "python"
    },
    "colab": {
      "name": "Assignment5_202011029.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwyPPSGTLJRK"
      },
      "source": [
        "# Extracting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIetKkglNSc2",
        "outputId": "e138d820-00be-4432-ca32-f23ec3d34a53"
      },
      "source": [
        "!gdown --id 1JuawXQmYVkjpfL3H0blqjDrqw8V1lHrC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JuawXQmYVkjpfL3H0blqjDrqw8V1lHrC\n",
            "To: /home/akarofl/Desktop/Projects/Makkhi/IR A5/FIRE_Dataset_EN_2010.rar\n",
            "133MB [00:23, 5.76MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNzK8PvlNSc8",
        "outputId": "156dce66-78ca-476d-cbf6-7a0b1a632106"
      },
      "source": [
        "!unrar x FIRE_Dataset_EN_2010.rar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.61 beta 1 freeware      Copyright (c) 1993-2018 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from FIRE_Dataset_EN_2010.rar\n",
            "\n",
            "Creating    FIRE_Dataset_EN_2010                                      OK\n",
            "Extracting  FIRE_Dataset_EN_2010/en.qrels.76-125.2010.txt.gz             0  OK \n",
            "Extracting  FIRE_Dataset_EN_2010/en.topics.76-125.2010.txt               0  OK \n",
            "Extracting  FIRE_Dataset_EN_2010/English-Data.tgz                             1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 6 7 7 7 8 8 8 9 9 9 99  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhtx-ls0NSc8",
        "outputId": "6df0b8ae-1b7e-42a0-cf13-321a81373a98"
      },
      "source": [
        "!tar -xvzf FIRE_Dataset_EN_2010/English-Data.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ry_7925796.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070722_sports_story_8091125.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070416_sports_story_7652990.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070310_sports_story_7497024.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070702_sports_story_8003930.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070523_sports_story_7817201.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070421_sports_story_7676644.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070325_sports_story_7562923.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070702_sports_story_8003598.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070227_sports_story_7445769.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070128_sports_story_7316676.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070222_sports_story_7424674.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070727_sports_story_8112983.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070320_sports_story_7541322.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070119_sports_story_7281837.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070831_sports_story_8258236.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070503_sports_story_7727605.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070712_sports_story_8048528.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070417_sports_story_7657165.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070924_sports_story_8353706.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070429_sports_story_7713003.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070420_sports_story_7672304.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070308_sports_story_7487810.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070601_sports_story_7860680.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070211_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070726_sports_story_8108072.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070516_sports_story_7784031.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070205_sports_story_7351081.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070417_sports_story_7657225.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070212_sports_story_7381096.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070129_sports_story_7320168.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070809_sports_story_8170073.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070202_sports_story_7339091.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070118_sports_story_7277551.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070925_sports_story_8357818.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070627_sports_story_7980213.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070730_sports_story_8124520.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070415_sports_story_7649973.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070109_sports_story_7237604.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070203_sports_story_7344031.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070626_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070321_sports_story_7544720.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070226_sports_story_7441366.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070704_sports_story_8013618.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070920_sports_story_8339290.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070924_sports_story_8353984.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070415_sports_story_7649813.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070428_sports_story_7707863.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070313_sports_story_7509582.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070117_sports_story_7272597.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070524_sports_story_7821601.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070609_sports_story_7899052.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070422_sports_story_7680184.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070811_sports_story_8179255.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070305_sports_story_7471246.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070512_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070430_sports_story_7716553.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070921_sports_story_8343521.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070823_sports_story_8226845.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070710_sports_story_8039111.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070711_sports_story_8043897.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070625_sports_story_7969945.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070627_sports_story_7980378.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070115_sports_story_7263267.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070614_sports_story_7921065.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070506_sports_story_7740456.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070624_sports_story_7966366.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070501_sports_story_7721398.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070825_sports_story_8235417.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070930_sports_story_8378338.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070211_sports_story_7378226.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070927_sports_story_8366840.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070202_sports_story_7339014.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070207_sports_story_7360734.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070414_sports_story_7646335.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070819_sports_story_8209838.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070106_sports_story_7226803.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070613_sports_story_7916399.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070208_sports_story_7364845.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070402_sports_story_7595869.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070828_sports_story_8245480.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070826_sports_story_8238739.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070107_sports_story_7230288.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070511_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070610_sports_story_7902661.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070929_sports_story_8375420.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070807_sports_story_8159933.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070823_sports_story_8226731.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070719_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070206_sports_story_7355795.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070827_sports_story_8241670.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070804_sports_story_8147975.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070831_sports_story_8257284.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070213_sports_story_7386376.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070317_sports_story_7528267.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070221_sports_story_7420240.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070210_sports_story_7374631.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070605_sports_story_7877789.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070514_sports_story_7774183.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070425_sports_story_7694633.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070201_sports_story_7334055.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070511_sports_story_7762464.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070804_sports_story_8147785.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070724_sports_story_8098905.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070518_sports_story_7794671.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070830_sports_story_8254413.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070624_sports_story_7966367.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070423_sports_story_7683904.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070320_sports_story_7541384.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070627_sports_story_7980371.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070731_sports_story_8128425.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070902_sports_story_8265890.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070923_sports_story_8350722.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070725_sports_story_8102999.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070125_sports_story_7306051.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070918_sports_story_8329981.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070524_sports_story_7821550.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070519_sports_story_7799563.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070630_sports_story_7995939.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070425_sports_story_7694495.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070831_sports_story_8258341.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070129_sports_story_7320174.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070404_sports_story_7604681.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070820_sports_story_8213480.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070424_sports_story_7689028.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070106_sports_story_7227250.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070205_sports_story_7351086.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070329_sports_story_7579529.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070214_sports_story_7391043.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070723_sports_story_8094092.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070112_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070222_sports_story_7425261.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070419_sports_story_7666508.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070219_sports_story_7410905.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070117_sports_story_7272374.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070908_sports_story_8291142.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070107_sports_story_7230406.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070528_sports_story_7840115.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070914_sports_story_8316273.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070430_sports_story_7717046.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070612_sports_story_7911361.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070225_sports_story_7438489.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070311_sports_story_7500779.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070624_sports_story_7966371.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070313_sports_story_7509571.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070121_sports_story_7290303.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070622_sports_story_7956366.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070605_sports_story_7877745.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070615_sports_story_7925734.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070315_sports_story_7519196.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070504_sports_story_7732630.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070917_sports_story_8325958.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070725_sports_story_8102997.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070803_sports_story_8143014.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070422_sports_story_7680183.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070111_sports_story_7246953.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070409_sports_story_7623934.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070605_sports_story_7877890.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070817_sports_story_8199476.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070704_sports_story_8013426.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070531_sports_story_7855126.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070628_sports_story_7985734.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070207_sports_story_7360735.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070920_sports_story_8339138.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070802_sports_story_8138646.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070806_sports_story_8155144.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070903_sports_story_8269006.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070329_sports_story_7580169.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070711_sports_story_8042315.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070418_sports_story_7661973.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070831_sports_story_8258345.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070903_sports_story_8269341.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070613_sports_story_7916471.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070228_sports_story_7451153.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070713_sports_story_8053313.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070630_sports_story_7996238.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070508_sports_story_7748199.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070408_sports_story_7621097.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070720_sports_story_8083129.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070521_sports_story_7807257.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070920_sports_story_8339026.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070724_sports_story_8098901.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070424_sports_story_7689602.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070224_sports_story_7434929.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070902_sports_story_8265934.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070620_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070103_sports_story_7214376.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070802_sports_story_8137979.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070420_sports_story_7672300.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070819_sports_story_8209880.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070330_sports_story_7583542.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070329_sports_story_7579848.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070310_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070110_sports_story_7242127.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070309_sports_story_7493320.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070302_sports_story_7460535.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070821_sports_story_8217527.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070720_sports_story_8083238.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070910_sports_story_8298135.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070603_sports_story_7869247.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070628_sports_story_7985731.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070203_sports_story_7343122.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070920_sports_story_8339376.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070722_sports_story_8091350.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070312_sports_story_7504809.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070717_sports_story_8068464.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070507_sports_story_7743732.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070309_sports_story_7490916.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070726_sports_story_8107776.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070902_sports_story_8265921.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070611_sports_story_7906380.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070122_sports_story_7293793.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070812_sports_story_8182670.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070923_sports_story_8350682.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070610_sports_story_7902664.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070805_sports_story_8151549.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070922_sports_story_8347407.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070508_sports_story_7748195.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070715_sports_story_8061121.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070217_sports_story_7404388.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070208_sports_story_7365383.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070409_sports_story_7623935.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070410_sports_story_7628570.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070903_sports_story_8269275.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070406_sports_story_7613100.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070830_sports_story_8254409.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070108_sports_story_7233435.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070106_sports_story_7227393.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070129_sports_story_7320208.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070706_sports_story_8023136.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070906_sports_story_8282440.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070829_sports_story_8249628.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070116_sports_story_7268015.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070518_sports_story_7794911.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070525_sports_story_7826697.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070308_sports_story_7487568.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070212_sports_story_7381130.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070814_sports_story_8190607.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070227_sports_story_7446316.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070208_sports_story_7365381.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070505_sports_story_7736970.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070302_sports_story_7460028.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070916_sports_story_8322983.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070704_sports_story_8013244.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070711_sports_story_8043668.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070326_sports_story_7566129.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070511_sports_story_7762456.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070524_sports_story_7823124.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070314_sports_story_7514102.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070112_sports_story_7251702.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070301_sports_story_7456008.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070320_sports_story_7541381.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070327_sports_story_7570546.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070614_sports_story_7920814.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070501_sports_story_7721281.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070829_sports_story_8250003.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070909_sports_story_8294689.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070317_sports_story_7529133.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070226_sports_story_7441512.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070719_sports_story_8075756.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070526_sports_story_7832221.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070412_sports_story_7638004.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070717_sports_story_8069121.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070318_sports_story_7533419.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070928_sports_story_8370757.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070806_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070907_sports_story_8287004.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070719_sports_story_8078491.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070317_sports_story_7529142.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070713_sports_story_8053636.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070421_sports_story_7676512.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070310_sports_story_7497094.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070424_sports_story_7689147.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070507_sports_story_7743726.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070828_sports_story_8245485.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070105_sports_story_7222938.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070925_sports_story_8355777.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070713_sports_story_8052333.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070508_sports_story_7748200.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070706_sports_story_8023141.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070209_sports_story_7369564.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070903_sports_story_8269300.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070812_sports_story_8182807.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070805_sports_story_8151833.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070512_sports_story_7767059.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070928_sports_story_8370917.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070112_sports_story_7252235.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070723_sports_story_8094513.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070805_sports_story_8151818.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070902_sports_story_8265984.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070413_sports_story_7642074.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070401_sports_story_7592518.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070917_sports_story_8325795.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070809_sports_story_8169657.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070117_sports_story_7272598.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070429_sports_story_7712906.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070412_sports_story_7637970.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070618_sports_story_7938035.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070421_sports_story_7676911.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070412_sports_story_7638007.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070515_sports_story_7778935.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070725_sports_story_8103114.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070615_sports_index.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070811_sports_story_8179076.utf8\n",
            "TELEGRAPH_UTF8/2007_utf8/sports/1070928_sports_story_8370795.utf8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29giK6jBNSc9"
      },
      "source": [
        "!gzip -d FIRE_Dataset_EN_2010/en.qrels.76-125.2010.txt.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piaH5ENALOhJ"
      },
      "source": [
        "# Importing libraries and downloading nltk packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_pb3tQeNSc9"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml.html\n",
        "import re\n",
        "import numpy as np    \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import bisect\n",
        "import math\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import scipy\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxY5uX1cNSc9",
        "outputId": "ed87f4ec-c85b-47e6-f48c-60e2d7d6719e"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/akarofl/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/akarofl/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/akarofl/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/akarofl/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAwCEUNyLQoZ"
      },
      "source": [
        "# Extracting data and storing in required formats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5S1gCNENSc-",
        "outputId": "01d95d84-590c-42ed-9925-06104ab292d6"
      },
      "source": [
        "files = [] # List is storing file name and file content. File content is a list of words.\n",
        "corpus = []\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "porter = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "postag = nltk.corpus.wordnet\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Returns Part of Speech for lemmatization\n",
        "def wordnet_pos(word):\n",
        "    t = nltk.pos_tag([word])[0][1][0].lower()\n",
        "    t_pos = {\"j\": postag.ADJ, \"n\": postag.NOUN, \"v\": postag.VERB, \"r\": postag.ADV}\n",
        "    return t_pos.get(t, postag.NOUN)\n",
        "i = 0\n",
        "for subdir, dirs, filenames in os.walk('TELEGRAPH_UTF8/'):\n",
        "    print('Progress: ',i)\n",
        "    for file_obj in filenames:\n",
        "      i = i+1\n",
        "      filename = os.path.join(subdir, file_obj)\n",
        "      # Extracting data and saving it to raw_text\n",
        "      soup = BeautifulSoup(open(filename, \"r\").read())\n",
        "      raw_text = soup.find('text').get_text()\n",
        "      for sym in raw_text : \n",
        "        # Removing punctuation\n",
        "        if sym in punc : \n",
        "          raw_text = raw_text.replace(sym, \"\")\n",
        "\n",
        "      # Removing non-alphabetic text and Converting text to lower-case\n",
        "      words = [word.lower() for word in raw_text.split() if word.isalpha()]\n",
        "      # Removing stopwords\n",
        "      words = [w for w in words if not w in stop_words]\n",
        "      # Performing lemmatization\n",
        "      lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
        "      temp_files = []\n",
        "      temp_files.append(filename)\n",
        "      temp_files.append(lemmatized)\n",
        "      # Storing file data to list\n",
        "      files.append(temp_files)\n",
        "      corpus.append(lemmatized)\n",
        "      # Appending data to 'files' list\n",
        "print(\"Total Documents: \", len(files))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress:  0\n",
            "Progress:  0\n",
            "Progress:  0\n",
            "Progress:  675\n",
            "Progress:  8290\n",
            "Progress:  10565\n",
            "Progress:  12283\n",
            "Progress:  15911\n",
            "Progress:  18148\n",
            "Progress:  20103\n",
            "Progress:  24403\n",
            "Progress:  30447\n",
            "Progress:  30447\n",
            "Progress:  30480\n",
            "Progress:  33434\n",
            "Progress:  33462\n",
            "Progress:  33513\n",
            "Progress:  34176\n",
            "Progress:  35090\n",
            "Progress:  35174\n",
            "Progress:  37289\n",
            "Progress:  37415\n",
            "Progress:  38579\n",
            "Progress:  39515\n",
            "Progress:  39534\n",
            "Progress:  39585\n",
            "Progress:  41800\n",
            "Progress:  41857\n",
            "Progress:  44791\n",
            "Progress:  44791\n",
            "Progress:  53896\n",
            "Progress:  55889\n",
            "Progress:  58543\n",
            "Progress:  64793\n",
            "Progress:  68121\n",
            "Progress:  70923\n",
            "Progress:  77355\n",
            "Progress:  85890\n",
            "Progress:  85890\n",
            "Progress:  95433\n",
            "Progress:  97786\n",
            "Progress:  99917\n",
            "Progress:  105419\n",
            "Progress:  108496\n",
            "Progress:  111250\n",
            "Progress:  117397\n",
            "Total Documents:  125586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWdff42TLVAj"
      },
      "source": [
        "# Training model using Gensim CBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zjuhIogNSc_",
        "outputId": "4b793239-6f75-4698-903d-01960a56020c"
      },
      "source": [
        "vect_size = 150\n",
        "\n",
        "print(\"Training with CBOW started...\")\n",
        "# Training Word2Vec model using CBOW \n",
        "cbow_model = Word2Vec(corpus, size = vect_size, min_count = 2,window = 10, sg = 0, hs = 1, iter = 5, workers = 10)\n",
        "\n",
        "print(\"Training with CBOW done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with CBOW started...\n",
            "Training with CBOW done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1STHnmALZmn"
      },
      "source": [
        "# Training model using Gensim CBOW\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqUOibBTNSc_",
        "outputId": "54764408-d833-4979-fe2f-df9bf80f0786"
      },
      "source": [
        "print(\"Creating vectors for Documents using CBOW word2vec ...\")\n",
        "# Calculating weighted average and forming document vectors\n",
        "count = 0\n",
        "doc_arr=[]\n",
        "for i in corpus:\n",
        "    demo = np.zeros((vect_size,),dtype = float) # initializing a zero matrix\n",
        "    for j in i:\n",
        "        try:\n",
        "            demo = demo + cbow_model.wv.__getitem__(j) # adding values of each token in doc to vector\n",
        "        except:\n",
        "          continue\n",
        "    count = count + 1\n",
        "    doc_arr.append(demo/len(i))\n",
        "    if count%1000 == 0:\n",
        "      print(\"Progress:\", count, \"/\", len(corpus))\n",
        "\n",
        "print(\"Vectors created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating vectors for Documents using CBOW word2vec ...\n",
            "Progress: 1000 / 125586\n",
            "Progress: 2000 / 125586\n",
            "Progress: 3000 / 125586\n",
            "Progress: 4000 / 125586\n",
            "Progress: 5000 / 125586\n",
            "Progress: 6000 / 125586\n",
            "Progress: 7000 / 125586\n",
            "Progress: 8000 / 125586\n",
            "Progress: 9000 / 125586\n",
            "Progress: 10000 / 125586\n",
            "Progress: 11000 / 125586\n",
            "Progress: 12000 / 125586\n",
            "Progress: 13000 / 125586\n",
            "Progress: 14000 / 125586\n",
            "Progress: 15000 / 125586\n",
            "Progress: 16000 / 125586\n",
            "Progress: 17000 / 125586\n",
            "Progress: 18000 / 125586\n",
            "Progress: 19000 / 125586\n",
            "Progress: 20000 / 125586\n",
            "Progress: 21000 / 125586\n",
            "Progress: 22000 / 125586\n",
            "Progress: 23000 / 125586\n",
            "Progress: 24000 / 125586\n",
            "Progress: 25000 / 125586\n",
            "Progress: 26000 / 125586\n",
            "Progress: 27000 / 125586\n",
            "Progress: 28000 / 125586\n",
            "Progress: 29000 / 125586\n",
            "Progress: 30000 / 125586\n",
            "Progress: 31000 / 125586\n",
            "Progress: 32000 / 125586\n",
            "Progress: 33000 / 125586\n",
            "Progress: 34000 / 125586\n",
            "Progress: 35000 / 125586\n",
            "Progress: 36000 / 125586\n",
            "Progress: 37000 / 125586\n",
            "Progress: 38000 / 125586\n",
            "Progress: 39000 / 125586\n",
            "Progress: 40000 / 125586\n",
            "Progress: 41000 / 125586\n",
            "Progress: 42000 / 125586\n",
            "Progress: 43000 / 125586\n",
            "Progress: 44000 / 125586\n",
            "Progress: 45000 / 125586\n",
            "Progress: 46000 / 125586\n",
            "Progress: 47000 / 125586\n",
            "Progress: 48000 / 125586\n",
            "Progress: 49000 / 125586\n",
            "Progress: 50000 / 125586\n",
            "Progress: 51000 / 125586\n",
            "Progress: 52000 / 125586\n",
            "Progress: 53000 / 125586\n",
            "Progress: 54000 / 125586\n",
            "Progress: 55000 / 125586\n",
            "Progress: 56000 / 125586\n",
            "Progress: 57000 / 125586\n",
            "Progress: 58000 / 125586\n",
            "Progress: 59000 / 125586\n",
            "Progress: 60000 / 125586\n",
            "Progress: 61000 / 125586\n",
            "Progress: 62000 / 125586\n",
            "Progress: 63000 / 125586\n",
            "Progress: 64000 / 125586\n",
            "Progress: 65000 / 125586\n",
            "Progress: 66000 / 125586\n",
            "Progress: 67000 / 125586\n",
            "Progress: 68000 / 125586\n",
            "Progress: 69000 / 125586\n",
            "Progress: 70000 / 125586\n",
            "Progress: 71000 / 125586\n",
            "Progress: 72000 / 125586\n",
            "Progress: 73000 / 125586\n",
            "Progress: 74000 / 125586\n",
            "Progress: 75000 / 125586\n",
            "Progress: 76000 / 125586\n",
            "Progress: 77000 / 125586\n",
            "Progress: 78000 / 125586\n",
            "Progress: 79000 / 125586\n",
            "Progress: 80000 / 125586\n",
            "Progress: 81000 / 125586\n",
            "Progress: 82000 / 125586\n",
            "Progress: 83000 / 125586\n",
            "Progress: 84000 / 125586\n",
            "Progress: 85000 / 125586\n",
            "Progress: 86000 / 125586\n",
            "Progress: 87000 / 125586\n",
            "Progress: 88000 / 125586\n",
            "Progress: 89000 / 125586\n",
            "Progress: 90000 / 125586\n",
            "Progress: 91000 / 125586\n",
            "Progress: 92000 / 125586\n",
            "Progress: 93000 / 125586\n",
            "Progress: 94000 / 125586\n",
            "Progress: 95000 / 125586\n",
            "Progress: 96000 / 125586\n",
            "Progress: 97000 / 125586\n",
            "Progress: 98000 / 125586\n",
            "Progress: 99000 / 125586\n",
            "Progress: 100000 / 125586\n",
            "Progress: 101000 / 125586\n",
            "Progress: 102000 / 125586\n",
            "Progress: 103000 / 125586\n",
            "Progress: 104000 / 125586\n",
            "Progress: 105000 / 125586\n",
            "Progress: 106000 / 125586\n",
            "Progress: 107000 / 125586\n",
            "Progress: 108000 / 125586\n",
            "Progress: 109000 / 125586\n",
            "Progress: 110000 / 125586\n",
            "Progress: 111000 / 125586\n",
            "Progress: 112000 / 125586\n",
            "Progress: 113000 / 125586\n",
            "Progress: 114000 / 125586\n",
            "Progress: 115000 / 125586\n",
            "Progress: 116000 / 125586\n",
            "Progress: 117000 / 125586\n",
            "Progress: 118000 / 125586\n",
            "Progress: 119000 / 125586\n",
            "Progress: 120000 / 125586\n",
            "Progress: 121000 / 125586\n",
            "Progress: 122000 / 125586\n",
            "Progress: 123000 / 125586\n",
            "Progress: 124000 / 125586\n",
            "Progress: 125000 / 125586\n",
            "Vectors created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQrBKiokYRsl"
      },
      "source": [
        "# Extracting Queries and storing in required formats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OEWIERmNSdA",
        "outputId": "a9003960-e1b1-491a-81cc-13b35c29e3c9"
      },
      "source": [
        "queries = []\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "porter = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "postag = nltk.corpus.wordnet\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "queryPath = \"FIRE_Dataset_EN_2010/en.topics.76-125.2010.txt\"\n",
        "tree = ET.parse(queryPath)\n",
        "root = tree.getroot()\n",
        "\n",
        "#Collecting Queries\n",
        "for records in root.findall('top'):\n",
        "    summary = records.find('num').text\n",
        "    full = records.find('title').text\n",
        "\n",
        "    words = [word.lower() for word in full.split() if word.isalpha()]\n",
        "    # Removing stopwords\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    # Performing lemmatization\n",
        "    lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    queries.append([summary, lemmatized])\n",
        "\n",
        "print(\"Queries Collected\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Queries Collected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCz_xAOXYUyN"
      },
      "source": [
        "# Creating vectors for queries using CBOW word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "kqd09RHNNSdA",
        "outputId": "92c2aab0-5e83-4c85-a998-8e64b50533c2"
      },
      "source": [
        "words = list(cbow_model.wv.vocab)\n",
        "q_arr = []\n",
        "count = 0\n",
        "\n",
        "print(\"Creating vectors for queries using CBOW word2vec ...\")\n",
        "\n",
        "for i in queries :\n",
        "  demo = np.zeros((vect_size,),dtype=float)\n",
        "  for j in i[1] :\n",
        "    if j in words :\n",
        "      demo = demo + cbow_model.wv.__getitem__(j)\n",
        "  count = count + 1\n",
        "  if count%20 == 0 : \n",
        "    print(\"Progress:\", count, \"/\", len(queries))\n",
        "  q_arr.append(demo/len(i[1]))\n",
        "\n",
        "print(\"Vectors created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating vectors for queries using CBOW word2vec ...\n",
            "Progress: 20 / 50\n",
            "Progress: 40 / 50\n",
            "Vectors created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0tpyA6ZYXZr"
      },
      "source": [
        "# Calculating cosine similarity and assigning ranks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUGmmd7SNSdB",
        "outputId": "e2c43e0e-4774-4816-c8f7-e6212ac458ac"
      },
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "print(\"Calculating Rankings of Docs for each query...\")\n",
        "\n",
        "r1 = []\n",
        "\n",
        "for i in range(len(q_arr)) :\n",
        "    rTemp = []\n",
        "    for j in range(len(doc_arr)) :\n",
        "        # Calculating cosine similarity for each query with every document\n",
        "        cos_sim = dot(q_arr[i], doc_arr[j])/(norm(q_arr[i])*norm(doc_arr[j]))\n",
        "        rTemp.append([files[j][0], cos_sim])\n",
        "    # Sorting the cosine similarity vector as per the highest similarity first        \n",
        "    rTemp.sort(key = lambda rTemp: rTemp[1], reverse=True) \n",
        "    r1.append(rTemp)\n",
        "\n",
        "    print(\"Progress: \", i+1, \" / \", len(q_arr))\n",
        "\n",
        "print(\"Ranking Complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Rankings of Docs for each query...\n",
            "Progress:  1  /  50\n",
            "Progress:  2  /  50\n",
            "Progress:  3  /  50\n",
            "Progress:  4  /  50\n",
            "Progress:  5  /  50\n",
            "Progress:  6  /  50\n",
            "Progress:  7  /  50\n",
            "Progress:  8  /  50\n",
            "Progress:  9  /  50\n",
            "Progress:  10  /  50\n",
            "Progress:  11  /  50\n",
            "Progress:  12  /  50\n",
            "Progress:  13  /  50\n",
            "Progress:  14  /  50\n",
            "Progress:  15  /  50\n",
            "Progress:  16  /  50\n",
            "Progress:  17  /  50\n",
            "Progress:  18  /  50\n",
            "Progress:  19  /  50\n",
            "Progress:  20  /  50\n",
            "Progress:  21  /  50\n",
            "Progress:  22  /  50\n",
            "Progress:  23  /  50\n",
            "Progress:  24  /  50\n",
            "Progress:  25  /  50\n",
            "Progress:  26  /  50\n",
            "Progress:  27  /  50\n",
            "Progress:  28  /  50\n",
            "Progress:  29  /  50\n",
            "Progress:  30  /  50\n",
            "Progress:  31  /  50\n",
            "Progress:  32  /  50\n",
            "Progress:  33  /  50\n",
            "Progress:  34  /  50\n",
            "Progress:  35  /  50\n",
            "Progress:  36  /  50\n",
            "Progress:  37  /  50\n",
            "Progress:  38  /  50\n",
            "Progress:  39  /  50\n",
            "Progress:  40  /  50\n",
            "Progress:  41  /  50\n",
            "Progress:  42  /  50\n",
            "Progress:  43  /  50\n",
            "Progress:  44  /  50\n",
            "Progress:  45  /  50\n",
            "Progress:  46  /  50\n",
            "Progress:  47  /  50\n",
            "Progress:  48  /  50\n",
            "Progress:  49  /  50\n",
            "Progress:  50  /  50\n",
            "Ranking Complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KKk674eYgbK"
      },
      "source": [
        "# Extracting qrels data and storing proper format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpKFzD37NSdB"
      },
      "source": [
        "file1 = open('FIRE_Dataset_EN_2010/en.qrels.76-125.2010.txt', 'r')\n",
        "Lines = file1.readlines()\n",
        "\n",
        "refDoc = []\n",
        "for line in Lines:\n",
        "    refDoc.append(line.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XofodWdxYi7I"
      },
      "source": [
        "# Calculating MAP score for CBOW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPao-Nt2NSdB"
      },
      "source": [
        "#List containing AP10 for each query\n",
        "AP10 = []\n",
        "\n",
        "for i in range(len(r1)):\n",
        "    cAP = 0\n",
        "    tAP = []\n",
        "    for j in range(min(10, len(r1[i]))):\n",
        "        for l in range(j):\n",
        "            docName = r1[i][j][0].split('/')[3]\n",
        "            queryNo = queries[i][0]\n",
        "\n",
        "            #Search for this doc in reference file\n",
        "            for k in range(len(refDoc)):\n",
        "                if(refDoc[k][0] == queryNo and refDoc[k][2] == docName and refDoc[k][3] == '1'):\n",
        "                    cAP = cAP + 1\n",
        "        tAP.append(cAP/(j+1))\n",
        "    avgP = 0\n",
        "    for val in tAP:\n",
        "        avgP += val\n",
        "    AP10.append(avgP/10)\n",
        "\n",
        "\n",
        "MAP10 = 0\n",
        "for ap in AP10:\n",
        "    MAP10 += ap\n",
        "\n",
        "MAP10 /= 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb2PeTYaNSdC",
        "outputId": "7e90750d-8325-45c6-cd3e-9cd7d2807bae"
      },
      "source": [
        "print('MAP using CBOW :', MAP10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAP using CBOW : 0.3055420634920635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml6PhHVcYnE6"
      },
      "source": [
        "# Creating vectors for Documents using Skipgram word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEvWZxO3NSdC",
        "outputId": "3f65fec2-cf58-456f-c434-f660f378c3f4"
      },
      "source": [
        "# Training Word2Vec model using Skipgram\n",
        "print(\"Training with Skip Gram started...\")\n",
        "sg_model = Word2Vec(corpus, size = vect_size, min_count = 2,window = 10, sg = 1, hs = 1, iter = 5, workers = 10)\n",
        "\n",
        "print(\"Training with Skip Gram done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with Skip Gram started...\n",
            "Training with Skip Gram done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2sVlUXCYqed"
      },
      "source": [
        "# Creating vectors for documents using SkipGram word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpcgO6xKNSdC",
        "outputId": "12ffe4fa-c735-4781-ad5f-0bf8e11cc1fb"
      },
      "source": [
        "import numpy as np    \n",
        "count = 0\n",
        "doc_arr=[]\n",
        "\n",
        "print(\"Creating vectors for Documents using Skip Gram word2vec ...\")\n",
        "\n",
        "for i in corpus:\n",
        "    demo = np.zeros((vect_size,),dtype = float)\n",
        "    for j in i:\n",
        "        try:\n",
        "            demo = demo + sg_model.wv.__getitem__(j)\n",
        "        except:\n",
        "          continue\n",
        "    count = count + 1\n",
        "    if count%1000 == 0:\n",
        "      print(\"Progress:\", count, \"/\", len(corpus))\n",
        "    doc_arr.append(demo/len(i))\n",
        "\n",
        "print(\"Vectors created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating vectors for Documents using Skip Gram word2vec ...\n",
            "Progress: 1000 / 125586\n",
            "Progress: 2000 / 125586\n",
            "Progress: 3000 / 125586\n",
            "Progress: 4000 / 125586\n",
            "Progress: 5000 / 125586\n",
            "Progress: 6000 / 125586\n",
            "Progress: 7000 / 125586\n",
            "Progress: 8000 / 125586\n",
            "Progress: 9000 / 125586\n",
            "Progress: 10000 / 125586\n",
            "Progress: 11000 / 125586\n",
            "Progress: 12000 / 125586\n",
            "Progress: 13000 / 125586\n",
            "Progress: 14000 / 125586\n",
            "Progress: 15000 / 125586\n",
            "Progress: 16000 / 125586\n",
            "Progress: 17000 / 125586\n",
            "Progress: 18000 / 125586\n",
            "Progress: 19000 / 125586\n",
            "Progress: 20000 / 125586\n",
            "Progress: 21000 / 125586\n",
            "Progress: 22000 / 125586\n",
            "Progress: 23000 / 125586\n",
            "Progress: 24000 / 125586\n",
            "Progress: 25000 / 125586\n",
            "Progress: 26000 / 125586\n",
            "Progress: 27000 / 125586\n",
            "Progress: 28000 / 125586\n",
            "Progress: 29000 / 125586\n",
            "Progress: 30000 / 125586\n",
            "Progress: 31000 / 125586\n",
            "Progress: 32000 / 125586\n",
            "Progress: 33000 / 125586\n",
            "Progress: 34000 / 125586\n",
            "Progress: 35000 / 125586\n",
            "Progress: 36000 / 125586\n",
            "Progress: 37000 / 125586\n",
            "Progress: 38000 / 125586\n",
            "Progress: 39000 / 125586\n",
            "Progress: 40000 / 125586\n",
            "Progress: 41000 / 125586\n",
            "Progress: 42000 / 125586\n",
            "Progress: 43000 / 125586\n",
            "Progress: 44000 / 125586\n",
            "Progress: 45000 / 125586\n",
            "Progress: 46000 / 125586\n",
            "Progress: 47000 / 125586\n",
            "Progress: 48000 / 125586\n",
            "Progress: 49000 / 125586\n",
            "Progress: 50000 / 125586\n",
            "Progress: 51000 / 125586\n",
            "Progress: 52000 / 125586\n",
            "Progress: 53000 / 125586\n",
            "Progress: 54000 / 125586\n",
            "Progress: 55000 / 125586\n",
            "Progress: 56000 / 125586\n",
            "Progress: 57000 / 125586\n",
            "Progress: 58000 / 125586\n",
            "Progress: 59000 / 125586\n",
            "Progress: 60000 / 125586\n",
            "Progress: 61000 / 125586\n",
            "Progress: 62000 / 125586\n",
            "Progress: 63000 / 125586\n",
            "Progress: 64000 / 125586\n",
            "Progress: 65000 / 125586\n",
            "Progress: 66000 / 125586\n",
            "Progress: 67000 / 125586\n",
            "Progress: 68000 / 125586\n",
            "Progress: 69000 / 125586\n",
            "Progress: 70000 / 125586\n",
            "Progress: 71000 / 125586\n",
            "Progress: 72000 / 125586\n",
            "Progress: 73000 / 125586\n",
            "Progress: 74000 / 125586\n",
            "Progress: 75000 / 125586\n",
            "Progress: 76000 / 125586\n",
            "Progress: 77000 / 125586\n",
            "Progress: 78000 / 125586\n",
            "Progress: 79000 / 125586\n",
            "Progress: 80000 / 125586\n",
            "Progress: 81000 / 125586\n",
            "Progress: 82000 / 125586\n",
            "Progress: 83000 / 125586\n",
            "Progress: 84000 / 125586\n",
            "Progress: 85000 / 125586\n",
            "Progress: 86000 / 125586\n",
            "Progress: 87000 / 125586\n",
            "Progress: 88000 / 125586\n",
            "Progress: 89000 / 125586\n",
            "Progress: 90000 / 125586\n",
            "Progress: 91000 / 125586\n",
            "Progress: 92000 / 125586\n",
            "Progress: 93000 / 125586\n",
            "Progress: 94000 / 125586\n",
            "Progress: 95000 / 125586\n",
            "Progress: 96000 / 125586\n",
            "Progress: 97000 / 125586\n",
            "Progress: 98000 / 125586\n",
            "Progress: 99000 / 125586\n",
            "Progress: 100000 / 125586\n",
            "Progress: 101000 / 125586\n",
            "Progress: 102000 / 125586\n",
            "Progress: 103000 / 125586\n",
            "Progress: 104000 / 125586\n",
            "Progress: 105000 / 125586\n",
            "Progress: 106000 / 125586\n",
            "Progress: 107000 / 125586\n",
            "Progress: 108000 / 125586\n",
            "Progress: 109000 / 125586\n",
            "Progress: 110000 / 125586\n",
            "Progress: 111000 / 125586\n",
            "Progress: 112000 / 125586\n",
            "Progress: 113000 / 125586\n",
            "Progress: 114000 / 125586\n",
            "Progress: 115000 / 125586\n",
            "Progress: 116000 / 125586\n",
            "Progress: 117000 / 125586\n",
            "Progress: 118000 / 125586\n",
            "Progress: 119000 / 125586\n",
            "Progress: 120000 / 125586\n",
            "Progress: 121000 / 125586\n",
            "Progress: 122000 / 125586\n",
            "Progress: 123000 / 125586\n",
            "Progress: 124000 / 125586\n",
            "Progress: 125000 / 125586\n",
            "Vectors created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prv1M9VJYvGo"
      },
      "source": [
        "Creating vectors for queries using SkipGram word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smNEvhnGNSdD",
        "outputId": "e55f7272-6ca3-4904-e434-17c104743df4"
      },
      "source": [
        "q_arr = []\n",
        "count = 0\n",
        "\n",
        "print(\"Creating vectors for queries using Skip Gram word2vec ...\")\n",
        "\n",
        "for i in queries :\n",
        "  demo = np.zeros((vect_size,),dtype=float)\n",
        "  for j in i[1] :\n",
        "    if j in words :\n",
        "      demo = demo + sg_model.wv.__getitem__(j)\n",
        "  count = count + 1\n",
        "  if count%20 == 0 : \n",
        "    print(\"Progress:\", count, \"/\", len(queries))\n",
        "  q_arr.append(demo/len(i[1]))\n",
        "\n",
        "print(\"Vectors created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating vectors for queries using Skip Gram word2vec ...\n",
            "Progress: 20 / 50\n",
            "Progress: 40 / 50\n",
            "Vectors created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyNRiFJ5Y67Z"
      },
      "source": [
        "# Calculating cosine similarity and assigning ranks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_028M9wNSdE",
        "outputId": "525e026b-4e02-4eee-8063-106ea9df3a47"
      },
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "print(\"Calculating Rankings of Docs for each query...\")\n",
        "\n",
        "r1 = []\n",
        "\n",
        "for i in range(len(q_arr)) :\n",
        "    rTemp = []\n",
        "    for j in range(len(doc_arr)) :\n",
        "        cos_sim = dot(q_arr[i], doc_arr[j])/(norm(q_arr[i])*norm(doc_arr[j]))\n",
        "        rTemp.append([files[j][0], cos_sim])\n",
        "        \n",
        "    rTemp.sort(key = lambda rTemp: rTemp[1], reverse=True) \n",
        "    r1.append(rTemp)\n",
        "\n",
        "    print(\"Progress: \", i+1, \" / \", len(q_arr))\n",
        "\n",
        "print(\"Ranking Complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Rankings of Docs for each query...\n",
            "Progress:  1  /  50\n",
            "Progress:  2  /  50\n",
            "Progress:  3  /  50\n",
            "Progress:  4  /  50\n",
            "Progress:  5  /  50\n",
            "Progress:  6  /  50\n",
            "Progress:  7  /  50\n",
            "Progress:  8  /  50\n",
            "Progress:  9  /  50\n",
            "Progress:  10  /  50\n",
            "Progress:  11  /  50\n",
            "Progress:  12  /  50\n",
            "Progress:  13  /  50\n",
            "Progress:  14  /  50\n",
            "Progress:  15  /  50\n",
            "Progress:  16  /  50\n",
            "Progress:  17  /  50\n",
            "Progress:  18  /  50\n",
            "Progress:  19  /  50\n",
            "Progress:  20  /  50\n",
            "Progress:  21  /  50\n",
            "Progress:  22  /  50\n",
            "Progress:  23  /  50\n",
            "Progress:  24  /  50\n",
            "Progress:  25  /  50\n",
            "Progress:  26  /  50\n",
            "Progress:  27  /  50\n",
            "Progress:  28  /  50\n",
            "Progress:  29  /  50\n",
            "Progress:  30  /  50\n",
            "Progress:  31  /  50\n",
            "Progress:  32  /  50\n",
            "Progress:  33  /  50\n",
            "Progress:  34  /  50\n",
            "Progress:  35  /  50\n",
            "Progress:  36  /  50\n",
            "Progress:  37  /  50\n",
            "Progress:  38  /  50\n",
            "Progress:  39  /  50\n",
            "Progress:  40  /  50\n",
            "Progress:  41  /  50\n",
            "Progress:  42  /  50\n",
            "Progress:  43  /  50\n",
            "Progress:  44  /  50\n",
            "Progress:  45  /  50\n",
            "Progress:  46  /  50\n",
            "Progress:  47  /  50\n",
            "Progress:  48  /  50\n",
            "Progress:  49  /  50\n",
            "Progress:  50  /  50\n",
            "Ranking Complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJxlmq2LY-xl"
      },
      "source": [
        "# Calculating MAP score for SkipGram model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIkqrLl_NSdF"
      },
      "source": [
        "#List containing AP10 for each query\n",
        "AP10 = []\n",
        "\n",
        "for i in range(len(r1)):\n",
        "    cAP = 0\n",
        "    tAP = []\n",
        "    for j in range(min(10, len(r1[i]))):\n",
        "        for l in range(j):\n",
        "            docName = r1[i][j][0].split('/')[3]\n",
        "            queryNo = queries[i][0]\n",
        "\n",
        "            #Search for this doc in reference file\n",
        "            for k in range(len(refDoc)):\n",
        "                if(refDoc[k][0] == queryNo and refDoc[k][2] == docName and refDoc[k][3] == '1'):\n",
        "                    cAP = cAP + 1\n",
        "        tAP.append(cAP/(j+1))\n",
        "    avgP = 0\n",
        "    for val in tAP:\n",
        "        avgP += val\n",
        "    AP10.append(avgP/10)\n",
        "\n",
        "\n",
        "MAP10 = 0\n",
        "for ap in AP10:\n",
        "    MAP10 += ap\n",
        "\n",
        "MAP10 /= 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlk1JIHCNSdF",
        "outputId": "4f299841-0722-46fa-adb3-58ff61ace00d"
      },
      "source": [
        "print('MAP using Skipgram :', MAP10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAP using Skipgram : 0.29238412698412697\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}