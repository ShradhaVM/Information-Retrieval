{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "202011029_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxT--SJdh9DD"
      },
      "source": [
        "Assignment 1 of Information Retrieval | \n",
        "Author: 202011029 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja4vxP9I3wk8"
      },
      "source": [
        "Importing all the libraries required for \n",
        "*   Extracting text data from mini dataset\n",
        "*   performing text cleaning operations with and without nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MUrgBzaKpjD"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml.html\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njQa31GM4HLl"
      },
      "source": [
        "Downloading required packages for tokenizing, removing stopwords, and performing lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWD5m4XAOh8U",
        "outputId": "004f5fe2-5159-400a-dd09-cad65787dd4b"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uVVmgqx4YI0"
      },
      "source": [
        "# Extacting Text from mini dataset\n",
        "This section extracts data using glob and os.path.join for iterating over files and using BeautifulSoup for extracting data within < TEXT > tags\n",
        "\n",
        "This section creates a file name testdata.txt and writes the combined data from mini dataset into that file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj8fsvRuNxPI"
      },
      "source": [
        "path = ''\n",
        "\n",
        "for file_obj in glob.glob(os.path.join(path, \"*.utf8\")) :\n",
        "    markup = (file_obj)\n",
        "    soup = BeautifulSoup(open(markup, \"r\").read())\n",
        "    with open(\"testdata.txt\", \"a\") as this_file :\n",
        "        this_file.write(soup.find('text').get_text())\n",
        "        this_file.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHFJ_u48458N"
      },
      "source": [
        "# Reading data from txt file\n",
        "This section reads data from testdata.txt and saves it in variable names raw_text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRU7_NelPypw"
      },
      "source": [
        "f_name = 'testdata.txt'\n",
        "f = open(f_name, 'rt')\n",
        "raw_text = f.read()\n",
        "f.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZLIJBOT5kmZ"
      },
      "source": [
        "# Cleaning of text begins from this section\n",
        "This section removes the punctuation and any words that contain non-alphabetic characters. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Variables named punc contains the set of punctuations that we want to remove and then we split raw_text to check if the words contain only alphabets using isalpha() function.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Finally, all the paragraphs are saved in variable named text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuiWVYcK1QQ2",
        "outputId": "0f3bb635-7691-4613-c3d8-ee37e1a96da1"
      },
      "source": [
        "# removing punctuation\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "for sym in raw_text : \n",
        "  if sym in punc : \n",
        "    raw_text = raw_text.replace(sym, \"\")\n",
        "\n",
        "#removing non-alphabetic words\n",
        "words = [word for word in raw_text.split() if word.isalpha()]\n",
        "text = ' '.join(words)\n",
        "print(text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Telegraph Calcutta Business New LIC pension plans A STAFF REPORTER Calcutta Sept Life Insurance Corporation of India LIC plans to unveil three new products including a unitlinked pension plan We have sought approval from the Insurance Regulatory and Development Authority of India IRDA for the approval of these three policies and will launch them soon after we receive it said LIC zonal manager D K Mehrotra Apart from the unitlinked pension plan the schemes would include a childrens plan and another similar to Jeevan Shree for high networth individuals Mehrotra acknowledged that the response to LICs existing pension schemes was not very encouraging This is because of lack of awareness among employees in rural and the unorganised sector said Mehrotra However the company is planning to increase awareness among these sections of people through a number of programmes to be addressed by agents and marketing people Mehrotra added Till August the corporation had sold a total of pension policies with a premium income of Rs crore In the eastern zone LIC had sold policies in the period between April and August with a total premium income of Rs crore During the financial year LIC had sold a total of lakh pension policies with a premium income of Rs crore in which the share of the eastern zone was policies and Rs crore in premium income Mehrotra said that the corporation would give special emphasis on increasing distribution channels to maintain its market share and also increase the popularity of pension schemes LIC markets its products through outlets of banks namely Uco Bank Corporation Bank Allahabad Bank West Bengal State Cooperative Bank and have licensed corporate agents who market the products through outlets As on August the eastern zone had earned premium income of Rs crore by selling lakh policies recording a growth of per cent and per cent in premium and policies respectively Bima Plus fetched premium of Rs crore and seven other important new plans earned premium of Rs crore The Telegraph Calcutta Business All eyes on Greenspan this week Greenspan In focus London Sept Reuters Federal Reserve chairman Alan Greenspans testimony on Capitol Hill midweek will be the main draw for global financial markets this week in the absence of significant data either side of the Atlantic analysts said Ruthlessly put Green spans testimony is the only real factor that matters next week for global foreign exchange and debt markets said Don Smith economist at ICAP in London Greenspan will speak before the House of Representatives budget committee next Wednesday The US August nonfarm payrolls report on Friday preserved the prospect of a rising Federal funds rate and analysts said it would lend support to the central bankers outlook for the worlds biggest economy Although employers added only to payrolls in August just below a median forecast of there were upward revisions to June and July data and debt markets dived after the figures The nonfarm payrolls dont change anything but they do provide Greenspan with more ammunition to say the economy is rebounding It will leave scope for further tightening of rates said Marc Ostwald bond broker at Monument Securities in London US rates were last hiked by basis points to per cent on August Before midyear they had nestled at per cent for a year and were at their lowest since the Greenspan will say that tightening is necessary to remove the unnecessary accommodation given to the market before which has resulted in negative real interest rates he added Since his testimony on July when he noted payrolls had averaged per month over the past six months the average reading slowed to in the three months to July said a research note on Friday from HSBC Bank But Greenspan is likely to blame recent disappointment on the high oil price And the recent pullback in energy prices could give him breathing roomto remain growth bullish the note added The Telegraph Calcutta Business RBI breather for urban coop banks OUR SPECIAL CORRESPONDENT Mumbai Sept The Reserve Bank has relaxed loan impairment norms for urban cooperative banks The norm relating to asset classification and provisioning will now be applicable to gold loans and small loans up to Rs lakh only from the financial year ending March Till then these loans would be governed by the impairment norm Earlier the central bank had advised UCBs to apply the norm from the financial year ending March The decision was based on the representations by UCBs a Reserve Bank release said here today RBI governor Y V Reddy had held meeting with federations of cooperative banks on September where UCBs sought relaxation in these norms In the meeting specific suggestions were placed These included a proposal to modify prudential regulations including deferring the application of norm a plan to exclude gold loans and loans below Rs lakh from these norms and to rationalise procedures governing maintenance of cash reserve ratio CRR The representatives also requested that the forthcoming Basel II norms are applied in a modified form to suit their localised nature The Telegraph Calcutta Business RBI fuels rally in bank stocks OUR SPECIAL CORRESPONDENT Mumbai Sept Bank shares rallied on the stock exchanges today after the Reserve Bank of India relaxed the limits on banks bond investments yesterday The RBI move is expected to have a positive impact on the balancesheet of public sector banks as it would cushion them against falling government security prices The RBI has allowed banks to exceed the per cent limit on their investments under the heldtomaturity HTM category provided the excess comprises only statutory liquidity ratio SLR securities The central bank also stipulated that the total SLR securities held in the HTM category should not be more than per cent of their demand and time liabilities DTL as on the last Friday of the second preceding fortnight According to analysts the RBI move will protect the balancesheets of nationalised banks from the impact of falling government security prices Nationalised banks are heavy investors in government securities and their investments exceed the minimum level of per cent of their deposits Presently there are three categories under which banks can hold securities These include HTM availableforsale and heldfortrading categories The RBI regulations stipulate that banks must mark to market their holdings in the availableforsale and heldfortrading categories Market circles said bank stocks which have been under pressure in the recent past on concerns over the impact of a likely rise in interest rates witnessed brisk buying with investors chasing nationalised banks At the BSE State Bank of India SBI was the most actively traded counter with the highest turnover of Rs crore SBI scrip firmed up by Rs to Rs Bank of Baroda also gained Rs to finish at Rs Corporation Bank shares were up by Rs to end at Rs and Canara Bank gained by Rs to finish at Rs The BSE Bankex was one of the leading indices in the exchange as it gained by around points After opening at it shot to a days high of before closing at The RBIs decision to raise the investment limits has come at a time when most of the banks have witnessed their trading gains evaporate in the first quarter of the current fiscal due to sustained drop in prices of government securities Treasury circles feel that the central bank is preparing the banking sector for an interest rate hike in the months to come So far the RBI has desisted from raising key rates and the benchmark bank rate is still at a three decade low The Telegraph Calcutta Business Advisers to help WBIDC sell bad assets SUTANUKA GHOSAL Calcutta Sept West Bengal Industrial Development Corporation WBIDC will appoint advisers to help it dispose of assets under liquidation The decision was taken at the corporations board meeting held last month There are such assets under liquidation and WBIDC wants to generate revenues from them The corporation will soon float a tender inviting bids from advisers who will be paid on a commission basis There are huge assets of nonperforming companies under liquidation WBIDC has exposure in these companies We want to unlock these idle assets and enhance revenue flow The advisers will help us in selling these assets The corporation will pay them good commissions said a senior WBIDC official WBIDC has consciously decided to increase its standard assets in order to reduce the net nonperforming asset and net asset ratio The corporation is planning to increase its exposure in the forthcoming projects In the last couple of years WBIDC had not invested heavily the last major being Rs crore in Ramrupai Steel Sources said the corporation may increase its exposure to Rs crore in certain projects At present there are three steel and a cement project on WBIDCs platter However the investment will all be in the form of loans WBIDC will not invest in equity in a big way Unless it is a very big project WBIDC will not pick up equity We will buy per cent of Kulpi Port which is being developed by the Bengal government P amp and Bengal Port sources added The corporation may also buy a stake in Tatas coke oven project which is slated to come up in Haldia In WBIDC had disbursed Rs crore as loans This year the target is Rs crore The corporation is also trying to cut its bad assets In WBIDC had trimmed its bad or nonperforming assets NPAs by Rs crore This year the target is Rs crore WBIDC has decided to raise money against its own receivables as part of the securitisation exercise ICICI Bank has agreed to provide Rs crore as loan against receivables at a coupon rate of per cent The corporation will lend this money at a higher interest of per cent thereby augmenting revenue for it State Bank of India as well as UTI Bank is keen to provide loans against receivables at an interest of per cent IDBI is also keen to provide us loans at a much lower interest of per cent We are in talks with them sources added\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrbdSAUu6T9k"
      },
      "source": [
        "# Tokenization\n",
        "This section performs tokenization using NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwazB5XAQBzU",
        "outputId": "9d89d669-9cc7-4277-9379-bb322be1043c"
      },
      "source": [
        "# tokenizing the text\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "print(*tokens[:40], sep = '\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "Telegraph\n",
            "Calcutta\n",
            "Business\n",
            "New\n",
            "LIC\n",
            "pension\n",
            "plans\n",
            "A\n",
            "STAFF\n",
            "REPORTER\n",
            "Calcutta\n",
            "Sept\n",
            "Life\n",
            "Insurance\n",
            "Corporation\n",
            "of\n",
            "India\n",
            "LIC\n",
            "plans\n",
            "to\n",
            "unveil\n",
            "three\n",
            "new\n",
            "products\n",
            "including\n",
            "a\n",
            "unitlinked\n",
            "pension\n",
            "plan\n",
            "We\n",
            "have\n",
            "sought\n",
            "approval\n",
            "from\n",
            "the\n",
            "Insurance\n",
            "Regulatory\n",
            "and\n",
            "Development\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHJf0cWy6nXb"
      },
      "source": [
        "# Normalizing case - Converting to lower\n",
        "This section converts text to lowercase using Python function lower()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di6_FPJERt3Q",
        "outputId": "df9a8901-06f6-46bc-8837-69bc18c22998"
      },
      "source": [
        "# normalizing case - converting to lower\n",
        "words = [word.lower() for word in words]\n",
        "print(*words[:40], sep = '\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n",
            "telegraph\n",
            "calcutta\n",
            "business\n",
            "new\n",
            "lic\n",
            "pension\n",
            "plans\n",
            "a\n",
            "staff\n",
            "reporter\n",
            "calcutta\n",
            "sept\n",
            "life\n",
            "insurance\n",
            "corporation\n",
            "of\n",
            "india\n",
            "lic\n",
            "plans\n",
            "to\n",
            "unveil\n",
            "three\n",
            "new\n",
            "products\n",
            "including\n",
            "a\n",
            "unitlinked\n",
            "pension\n",
            "plan\n",
            "we\n",
            "have\n",
            "sought\n",
            "approval\n",
            "from\n",
            "the\n",
            "insurance\n",
            "regulatory\n",
            "and\n",
            "development\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjOWeZy06xY3"
      },
      "source": [
        "# Filtering out Stopwords\n",
        "This section removes stopwords using NLTK english stopwords corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "penW-3bWNz4O",
        "outputId": "a125d8bf-cfa6-4808-e508-fc9e5a4c62f5"
      },
      "source": [
        "# filtering out stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [w for w in words if not w in stop_words]\n",
        "print(*words[:40], sep = '\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "telegraph\n",
            "calcutta\n",
            "business\n",
            "new\n",
            "lic\n",
            "pension\n",
            "plans\n",
            "staff\n",
            "reporter\n",
            "calcutta\n",
            "sept\n",
            "life\n",
            "insurance\n",
            "corporation\n",
            "india\n",
            "lic\n",
            "plans\n",
            "unveil\n",
            "three\n",
            "new\n",
            "products\n",
            "including\n",
            "unitlinked\n",
            "pension\n",
            "plan\n",
            "sought\n",
            "approval\n",
            "insurance\n",
            "regulatory\n",
            "development\n",
            "authority\n",
            "india\n",
            "irda\n",
            "approval\n",
            "three\n",
            "policies\n",
            "launch\n",
            "soon\n",
            "receive\n",
            "said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn2K35887b9g"
      },
      "source": [
        "# Stemming using PorterStemmer\n",
        "This section uses PorterStemmer for performing stemming on words/tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrLfQ632SYmd",
        "outputId": "bddc0761-e917-406a-8e3b-e03a91563c60"
      },
      "source": [
        "# stemming words\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "stemmed = [porter.stem(word) for word in words]\n",
        "print(\"{:<15}{:^10}{:>15}\".format('Normal', ':', 'Stemmed'))\n",
        "print('\\n')\n",
        "for i in range(0,40):\n",
        "  print(\"{:<15}{:^10}{:>15}\".format(words[i], ':', stemmed[i]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal             :             Stemmed\n",
            "\n",
            "\n",
            "telegraph          :           telegraph\n",
            "calcutta           :            calcutta\n",
            "business           :                busi\n",
            "new                :                 new\n",
            "lic                :                 lic\n",
            "pension            :             pension\n",
            "plans              :                plan\n",
            "staff              :               staff\n",
            "reporter           :              report\n",
            "calcutta           :            calcutta\n",
            "sept               :                sept\n",
            "life               :                life\n",
            "insurance          :               insur\n",
            "corporation        :              corpor\n",
            "india              :               india\n",
            "lic                :                 lic\n",
            "plans              :                plan\n",
            "unveil             :              unveil\n",
            "three              :               three\n",
            "new                :                 new\n",
            "products           :             product\n",
            "including          :              includ\n",
            "unitlinked         :            unitlink\n",
            "pension            :             pension\n",
            "plan               :                plan\n",
            "sought             :              sought\n",
            "approval           :              approv\n",
            "insurance          :               insur\n",
            "regulatory         :          regulatori\n",
            "development        :             develop\n",
            "authority          :              author\n",
            "india              :               india\n",
            "irda               :                irda\n",
            "approval           :              approv\n",
            "three              :               three\n",
            "policies           :              polici\n",
            "launch             :              launch\n",
            "soon               :                soon\n",
            "receive            :              receiv\n",
            "said               :                said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ3qodT679OF"
      },
      "source": [
        "# Lemmetization using WordNetLemmatizer\n",
        "This section performs Lemmetization using WordNetLemmatizer. It also uses wordnet of nltk corpus for identifying whether a word is a noun, adjective, verb or an adjective. This is required so that root could be properly identified for lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRV59J5lUB69",
        "outputId": "74729991-c24f-446e-8a68-175a8abc8ba8"
      },
      "source": [
        "#lemmatizing words\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "postag = nltk.corpus.wordnet\n",
        "\n",
        "def wordnet_pos(word):\n",
        "    t = nltk.pos_tag([word])[0][1][0].lower()\n",
        "    t_pos = {\"j\": postag.ADJ, \"n\": postag.NOUN, \"v\": postag.VERB, \"r\": postag.ADV}\n",
        "    return t_pos.get(t, postag.NOUN)\n",
        "\n",
        "lemmatized = [lemmatizer.lemmatize(word, wordnet_pos(word)) for word in words]\n",
        "print(\"{:<15}{:^10}{:>15}\".format('Normal', ':', 'Lemmetized'))\n",
        "print('\\n')\n",
        "for i in range(0,40):\n",
        "    print(\"{:<15}{:^10}{:>15}\".format(words[i], ':', lemmatized[i]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal             :          Lemmetized\n",
            "\n",
            "\n",
            "telegraph          :           telegraph\n",
            "calcutta           :            calcutta\n",
            "business           :            business\n",
            "new                :                 new\n",
            "lic                :                 lic\n",
            "pension            :             pension\n",
            "plans              :                plan\n",
            "staff              :               staff\n",
            "reporter           :            reporter\n",
            "calcutta           :            calcutta\n",
            "sept               :                sept\n",
            "life               :                life\n",
            "insurance          :           insurance\n",
            "corporation        :         corporation\n",
            "india              :               india\n",
            "lic                :                 lic\n",
            "plans              :                plan\n",
            "unveil             :              unveil\n",
            "three              :               three\n",
            "new                :                 new\n",
            "products           :             product\n",
            "including          :             include\n",
            "unitlinked         :          unitlinked\n",
            "pension            :             pension\n",
            "plan               :                plan\n",
            "sought             :              sought\n",
            "approval           :            approval\n",
            "insurance          :           insurance\n",
            "regulatory         :          regulatory\n",
            "development        :         development\n",
            "authority          :           authority\n",
            "india              :               india\n",
            "irda               :                irda\n",
            "approval           :            approval\n",
            "three              :               three\n",
            "policies           :              policy\n",
            "launch             :              launch\n",
            "soon               :                soon\n",
            "receive            :             receive\n",
            "said               :                 say\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUV3xASR84k5"
      },
      "source": [
        "# Comparison between Stemmed words and Lemmatized words\n",
        "This section observes difference between stemming and lemmatization. It can be efficiently concluded that lemmatization seems to add a level of word meaning over stemming. Stemming provides truly rooted words which in some cases, gives inaccurate output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYTvE8X9eZyk",
        "outputId": "acf16728-f1a7-4997-9c40-b66dc43e7cfe"
      },
      "source": [
        "print(\"{:<15}{:^10}{:>15}\".format('Stemmed', ':', 'Lemmetized'))\n",
        "print('\\n')\n",
        "for i in range(0,40):\n",
        "    print(\"{:<15}{:^10}{:>15}\".format(stemmed[i], ':', lemmatized[i]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemmed            :          Lemmetized\n",
            "\n",
            "\n",
            "telegraph          :           telegraph\n",
            "calcutta           :            calcutta\n",
            "busi               :            business\n",
            "new                :                 new\n",
            "lic                :                 lic\n",
            "pension            :             pension\n",
            "plan               :                plan\n",
            "staff              :               staff\n",
            "report             :            reporter\n",
            "calcutta           :            calcutta\n",
            "sept               :                sept\n",
            "life               :                life\n",
            "insur              :           insurance\n",
            "corpor             :         corporation\n",
            "india              :               india\n",
            "lic                :                 lic\n",
            "plan               :                plan\n",
            "unveil             :              unveil\n",
            "three              :               three\n",
            "new                :                 new\n",
            "product            :             product\n",
            "includ             :             include\n",
            "unitlink           :          unitlinked\n",
            "pension            :             pension\n",
            "plan               :                plan\n",
            "sought             :              sought\n",
            "approv             :            approval\n",
            "insur              :           insurance\n",
            "regulatori         :          regulatory\n",
            "develop            :         development\n",
            "author             :           authority\n",
            "india              :               india\n",
            "irda               :                irda\n",
            "approv             :            approval\n",
            "three              :               three\n",
            "polici             :              policy\n",
            "launch             :              launch\n",
            "soon               :                soon\n",
            "receiv             :             receive\n",
            "said               :                 say\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}